#+Title: 400A - Neutrinos & computational stellar evolution
#+author: Mathieu Renzo
#+email: mrenzo@arizona.edu

* Neutrino physics in stars
*Materials:* Sec. 6.5 and 12.3.1 of Onno Pols' notes.

We have almost seen all the pieces needed to make a one-dimensional
hydrostatic model of a star, including the input physics in the
quantities \kappa (opacity) and \varepsilon_{nuc}. The aim of this lecture is to unpack
the last input quantities entering in the energy conservation which
connects stellar physics with neutrino physics: \varepsilon_{\nu.}

** Summary of equations we have derived

*** Mass conservation
#+begin_latex
\begin{equation}\label{eq:mass_cont}
\frac{dr}{dm} = \frac{1}{4\pi r^{2}\rho}\ \ .
\end{equation}
#+end_latex

*** Hydrostatic equilibrium
#+begin_latex
\begin{equation}\label{eq:HSE}
\frac{dP}{dm} = -\frac{Gm}{4\pi r^{4}} \ \ ,
\end{equation}
#+end_latex
which follows from the momentum conservation equation assuming the
acceleration to be negligible *N.B.:* this last assumption could be
relaxed to add an extra term in this equation analogous to ma in F=ma.

*** Equation of state
#+begin_latex
\begin{equation}
P_\mathrm{tot} = P_\mathrm{gas} + P_\mathrm{rad} = \frac{\rho}{\mu m_{u}}k_{B}T + P_{QM} + \frac{1}{3}aT^{4}  \ \ .
\end{equation}
#+end_latex

*** Energy transport
#+begin_latex
\begin{equation}
\frac{dT}{dm} = \frac{T}{P}\frac{dP}{dm}\nabla
\end{equation}
#+end_latex
where \nabla =\partial log(T)/\partial log(P) is the local temperature gradient, equal to
the radiative gradient in stably stratified regions:
#+begin_latex
\begin{equation}
\nabla \equiv \nabla_\mathrm{rad} = \frac{3 P}{14\pi acGm T^{4}}\kappa L
\end{equation}
#+end_latex
with \kappa = (1/\kappa_{rad} + 1/\kappa_{cond})^{-1} the combination "in parallel" of the
radiative and conductive opacity (assumed to be known from atomic
physics), and \nabla \equiv \nabla_{ad} the adiabatic gradient (within \sim10^{-7-8}
precision) for convective regions. We also have a criterion
(Schwarzschild criterion) to determine which region is which.

*** Energy conservation
#+begin_latex
\begin{equation}
\frac{dL}{dm} = \varepsilon_\mathrm{nuc} -\varepsilon_{\nu} + \varepsilon_\mathrm{grav} \ \ .
\end{equation}
#+end_latex

with \varepsilon_{grav} = T\partial s/\partial t the change in internal energy and \varepsilon_{\nu}>0.

** Two types of neutrinos

For the \rho typical in stars (think of \langle\rho_{\odot}\rangle and the other
average densities you estimated in the various homeworks), neutrinos
can safely be considered as non-interacting. This means we can
consider neutrinos as ultra-relativistic mass-less particles
propagating at v \simeq c. The mass less approximation also implies that we
neglect neutrino oscillations: even if a neutrino changes leptonic
flavor, it's still going to leave the star carrying away its energy!

Therefore, any neutrino produced in the stellar interior leaves the
star in the light-crossing time R/c \le 1000 R_{\odot}/c \simeq 1000 \times
2 sec = 2000 sec which is much shorter than evolutionary timescales
(and even during shorter evolutionary phases such as silicon shell
burning, the energy carried by the neutrinos is on its way out and
nothing is going to stop it from leaving the star).

These arguments apply to both kinds of neutrinos that we can encounter
in stellar evolution, and stop working only when densities get
extremely high (\rho\ge10^{10} g cm^{-3}): at this point neutrinos can and do
start interacting with matter. Such densities are only encountered in
a collapsing core that has exhausted nuclear fuel and in neutron
stars: neutrino interactions are crucial to the physics of the
supernova explosions, but can safely be neglected before.

During the evolution of the star that sets the stage for the
explosion, we encounter two "classes" of neutrinos.

*** Nuclear neutrinos
We have already encountered processes occurring in stars: /weak nuclear
reactions/! These are needed since the main sequence (both in the pp
chain and CNO) to convert some protons into neutrons for the helium
nuclei. On the scale of r_{nuc}, the neutrino crossing time (that is the
light crossing time) is so short that we can neglect neutrino
oscillations and assume conservation of leptonic number to write down
the equations.

*N.B.:* recall that the leptonic number is +1 for the leptons electron
e^{-}, muon \mu^{-}, tau \tau^{-} and the corresponding neutrinos \nu_{e}, \nu_{\mu},
\nu_{\tau} and -1 for their antiparticles positron e^{+}, positive muon \mu^{+},
and positive \tau^{+} and the corresponding antineutrinos.

These neutrinos do carry away energy as described above, /but/ that is
just some of the energy that the exo-energetic thermonuclear reaction
would have released. Effectively, they decrease the energy gain from
releasing nuclear binding energy but they are not a net energy loss.

This allows to incorporate them in models by re-writing \varepsilon_{nuc}
\rightarrow \varepsilon_{nuc} - |\varepsilon_{\nu, nuc}|, where the neutrino term is always negative
(hence we can write it as minus an absolute value), and needs to be
calculated from nuclear physics, determining the spectrum of the
neutrino produced by a given reaction (a non-trivial task which
stellar physics leaves to neutrinos and nuclear physicists).

Particularly important for the late evolution of massive stars are
neutrinos from the so-called /URCA processes/ (named after a casino in
Rio de Janeiro because when these processes kick in the energy of the
nuclear reaction goes the same way as the money in the casino!):
#+begin_latex
\begin{equation}
 ^{A}Z+e^{-}\rightarrow^{A}(Z-1) + \nu_{e }\\
 ^{A}(Z-1)\rightarrow ^{A}Z+ e^{+} +\bar{\nu_{e}}
\end{equation}
#+end_latex

which produce one neutrino and one anti-neutrino without changing the
composition of the star. This requires that the nucleus $^{A}(Z-1)$ is
unstable to \beta^{-}-decay and the cross section for electron capture on
$^AZ$ is non-negligible, which can happen during Si core burning and
the subsequent gravitational collapse of the core once the nuclear
fuel runs out.

The nuclear neutrinos are mostly sensitive to the core temperature for
the activation of certain thermonuclear reaction chains (except for
pycno-nuclear reaction at extremely high densities where the electron
screening effectively makes the Coulomb barrier negligible).

*** Thermal neutrinos
After helium core burning, the density in the stellar cores become
sufficiently high (because of the gravothermal collapse) that
non-nuclear processes producing neutrinos start occurring. After
carbon depletion, the neutrinos produced by these processes can take
away more energy than is locally lost to photons by each stellar
layer: /evolved massive stars are neutrino stars/ L_{\nu}
\gg L_{rad} ([[https://ui.adsabs.harvard.edu/abs/1968Ap%26SS...2...96F/abstract][Fraley 1968]]).

This also effectively means that the stellar core of evolved (\sim during
and after carbon core burning) massive stars is /decoupled/ from the
stellar envelope: the /gravothermal collapse of the core occurs to
compensate the neutrino losses from the core itself/! The thermal
timescale of the core becomes \tau_{KH,\nu}\simeq GM_{core}^{2}/(2R_{core} L_{\nu}) and
the nuclear timescale becomes \tau_{nuc,\nu} = \phi f_{burn} Mc^{2}/L_{\nu} both of which
are much shorter than the timescales in the low density, photon-cooled
envelope: in the late stages of stellar evolution the envelope should
be /frozen/ and the core evolves driven by neutrino losses.

*N.B.:* it is still the energy losses driving the gravothermal collapse
because of the virial theorem that govern the evolution, but the
envelope does not have time to keep up with the core.

*N.B.:* recently, observations of early signals of stellar explosion
have questioned this picture of /frozen/ envelope: there /may/ be some
presently unknown phenomena happening on a /dynamical/ timescale of the
envelope in the final years/months of a massive star evolution that
affect the envelope. The fact that they /need to be dynamical/ to do
anything is related to the fact that the evolution of the core is sped
up by the thermal neutrino losses.

The neutrinos that do /not/ come from nuclear reactions are a real
energy /loss/ term for the star that enter in the local energy
conservation equation \varepsilon_{\nu}_{} (which is also always negative!): dL/dm =
\varepsilon_{nuc} - |\varepsilon_{\nu}| +\varepsilon_{grav}.

The /thermal/ processes producing these neutrinos typically will produce
a neutrino-antineutrino /pair/ to conserve the leptonic number.
Typically only electron neutrinos will be relevant: leptons other than
e^{\pm} are unstable and are not commonly found in stars. They fall into
several categories:


#+CAPTION: Feynman diagrams for the dominant neutrino cooling processes. The top row shows the photo-emission processes, the middle row shows the eÂ± annihilation processes, the bottom row shows the plasmon processes. The neutral (charged) current ractions are in the left (right) column. This is Figure 1 from [[https://ui.adsabs.harvard.edu/abs/1993ApJ...411..813A/abstract][Aufderheide 1993]], and Z and W represent the boson that mediate weak interactions: the left column shows interactions mediated by the neutral boson Z, while the right column shows interactions mediated by the charged boson W^{\pm}.
#+ATTR_HTML: :width 100%
[[./images/feynman_diagram_neutrinos.png]]

  - plasmon processes: $\gamma + \tilde{\gamma} \rightarrow \nu_x + \bar{\nu}_x$,
  - bremsstrahlung: $e^{-} + ^{A}Z \rightarrow e^{-} + ^{A}Z + \nu_x + \bar{\nu}_x$,
  - pair-production: $\gamma + \gamma \rightarrow \nu_x + \bar{\nu}_x$,
  - pair annihilation:  $e^{+}+e^{-} \rightarrow \nu_x + \bar{\nu}_x$ ,
  - photo-processes: $\gamma +e^{-} \rightarrow e^{-} + \nu_x + \bar{\nu}_x$,

*N.B.:* "plasmons" are collective excitations of the stellar plasma that
propagate (the analogy is with "solitons" in fluid dynamics).

*N.B.:* The Feynman diagrams of some of these processes above are
illustrating the processes (and the various pieces that contribute in
the quantum field theory calculation of the cross section), the
particles that are not "free legs" are mediators and not real
particles, do not over-interpret these diagrams as physical pictures!

Neutrino cooling processes are mostly sensitive to the core density \rho.
The typical energy carried away per neutrino-antineutrino pair is of
the order of the thermal energy of the electrons (i.e., their Fermi
energy if the region from where the neutrinos are emitted is partially
degenerate).

Lke \kappa and \varepsilon_{nuc}, the energy losses to thermal neutrinos are usually
tabulated in stellar physics codes (see especially the widely used
[[https://ui.adsabs.harvard.edu/abs/1996ApJS..102..411I/abstract][Itoh et al. 1996]]), and the figure below shows the |\varepsilon_{\nu}|
\equiv |\varepsilon_{\nu}|(T,\rho) resulting from these tables:

#+CAPTION: Neutrino energy losses on the T(\rho) plane. White lines mark the separation between regions where different neutrino emission processes dominate, the colored lines mark the T(\rho) tracks of helium cores of the labeled masses (in M_{\odot} units) computed with MESA. Credits: R. Farmer.
#+ATTR_HTML: :width 100%
[[./images/Trho_neutrinos.png]]

* Principles of computational stellar evolution

We now have finally derived/discussed all the pieces of physics
necessary to compute a stellar /structure/ model, treat its nuclear
energy generation and thus driving its /evolution/.

The description we have obtained for a spherically symmetric star is
made of *four non-linear, coupled, ordinary differential equations*
(ODE) *plus the equation of state that acts as closure condition* for
the system. Solving these equations we can:
 1. study the interior structure of modelled stars and try to learn about
    the parts of the star that are not accessible to direct
    observations (hidden inside the photosphere)
 2. study the time evolution of modelled stars, which we cannot
    observe for real stars since most evolve way too slow for us to
    follow within our lifetimes.

However, this system of coupled, non-linear ODEs is not easily solved
by hand. Since the early days of the availability of computers in the
1960s, people have been designing and leveraging /computational
techniques/ to /numerically/ solve this system of equations (see e.g.,
[[https://ui.adsabs.harvard.edu/abs/1962ApJ...135..770I/abstract][Iben & Erhman 1962]], [[https://ui.adsabs.harvard.edu/abs/1964ApJ...139..306H/abstract][Henyey 1964]]). For the rest of this lecture, we are
going to discuss some general principles behind these computational
techniques.

** The most important thing: /Computer simulations are not empirical evidence/

:Quote:
"/Traditional scientific knowledge has generally taken the form of/
/either theory or experimental data. However, where theory and/
/experiment stumble, simulations may offer a third way./" - Simulation,
Johannes Lenhard et al.
:end:

Computational techniques take a system of equations describing a
physical models (for example the equations we have derived), which
already rely on a whole variety of physical approximations (e.g.,
spherical symmetry, LTE, free-streaming neutrinos, etc.), and apply a
whole new set of /numerical/ approximations to obtain a numerical
solution.

Presumably, nature does not do /any/ of this: without opening the
philosophical question of whether nature writes down equations to
solve, it certainly does not need to make physical approximations
(while we need to do it to reason on a problem and keep it
manageable), and even less make /numerical/ approximations needed to
solve equations. At ontological level, numerical simulations are /not/
equivalent to empirical evidence! Never trust numerical results as if
they were ground truth: a computer will only do what it is told, and
we tell it our physically and numerically approximated best guess for
what we are trying to simulate which is /not/ what nature empirically
provides. I emphasize this as a person who spends most of his time
making numerical simulations! Note also how this is more general than
/just/ stellar physics: this applies to /any/ computational physics field.

Because of these, it is always crucially important to /do resolution
tests/: when performing a simulation of a physical phenomenon, you
should always test that the scientific results you obtain do not
depend on how you discretize your equations in time and space and on how
you numerically solve them. This is often a painful task, but very
important to not fool ourselves!

:Quote:
"All models are wrong, but some are useful!" - G. Box
:end:

In stellar physics, there is another problem: the /high non-linearity/
of the coupled system of ODEs means that there can be chaotic
behavior! A small perturbation (maybe because of a numerical error or
a small inconsistency in the tabulated input physics!) can cascade
into dramatic consequences, similar to the famous "butterfly effect"
(which was also theorized from numerical computations, but of
atmospheric physics, by [[https://en.wikipedia.org/wiki/Edward_Norton_Lorenz][E. Lorenz]]).


** Why did we limit ourselves to spherical symmetry?
Throughout the course so far we have explicitly assumed spherical
symmetry, although since the beginning we have discussed some
phenomena that can break the global spherical symmetry (e.g.,
rotation, magnetic fields, or the presence of gravity and/or
irradiation from companion stars), and we have seen phenomena (e.g.,
convection) that break the spherical symmetry locally. Without the
assumption of spherical symmetry, the equations describing our system
would become partial differential equations (PDE), changing the
mathematical and thus computational approach.

In some cases, it is possible to treat some of these by casting them
in a form that still allows a 1D formalism with ODEs (e.g., "shellular
rotation" assuming that all quantities are constant along isobars and
uses P as the independent coordinate, or using volume-weighted
equivalent potentials accounting for the gravity of a companion star).
But ultimately the physics is non-spherical, so why do we insist with
this limited approximation?

The main reason is /necessity/ (see for example [[https://ui.adsabs.harvard.edu/abs/2022ApJS..262...19J/abstract][Jermyn et al. 2022
section 5.4]]) *the contrast of scale in both space and time* required to
follow the /evolution/ of a star from birth to death (or to the current
age of the Universe, whichever comes first!) *is just too large* to be
manageable with present day /and/ with foreseeable computational
capabilities.

*** Spatial scale limitations

Consider the convective envelope in the Sun. It has a Reynolds number
Re= v_{conv} \ell/\nu \sim 10^{12}, which, using Kolmogorov's model of
turbulence implies that the turbulent cascade spans a range of scales
from L to \ell with a contrast L/\ell \sim Re^{3/4} \sim 10^{9}. To resolve this
contrast in a 3D simulation we would need this number of cells /in
each direction/, meaning \sim10^{27} points.

*** Temporal scale limitations
Consider again the Sun. The free fall timescale is generously
\tau_{ff}\sim1h, and its thermal timescale is \tau_{KH}\sim1.5\times10^{7} years,
and current age is \sim 5\times10^{9} years \simeq \tau_{nuc}. In 3D we would need to
resolve the dynamics of the gas, with timesteps \Delta t \leq \tau_{ff}. Even
considering an equal sign \Delta t=\tau_{ff} (certainly insufficient to /resolve/
the dynamics of the stellar plasma), it would take \sim \tau_{Kh} / \tau_{ff} = 10^{10}
timesteps to calculate a thermal timescale and \sim \tau_{nuc} / \tau_{ff} = 10^{12}
timesteps for a nuclear timescale.

*** Present day and future prospects

The largest present day multi-dimensional stellar hydrodynamics
simulations reach maybe up to 10^{12} resolution points, and about 10^{8}
timesteps and using lower-than-realistic Reynolds number and/or
boosting the luminosity to drive dynamical effects faster than in
reality (see [[https://ui.adsabs.harvard.edu/abs/2022ApJ...928L..10A/abstract][Anders et al. 2022]] or [[https://ui.adsabs.harvard.edu/abs/2024MNRAS.531.1316T/abstract][Thompson et al. 2024]]).

Assuming that Moore's law (the number of transistors in a CPU roughly
doubles every year) - an assumptions that may clash with the
engineering reality, it will take several decades to have a
numerically resolved 3D simulation of convection in a star for a
convective turnover timescale, and longer for thermal and nuclear
timescale: 1D will remain necessary.

Nevertheless, 3D stellar hydrodynamics of restricted problems ("box in
a star" approach, short timescales such as stellar explosions) are
possible, and stellar /structure/ simulations in 2D are also at the
forefront of possibilities (see e.g., [[https://ui.adsabs.harvard.edu/abs/2023A%26A...677L...5M/abstract][Mombarag et al. 2023]]).

** Boundary conditions

** Solving strategies

*** Shooting method

*** Henyey method

*** Evolution splitting


** Open science: [[https://docs.mesastar.org/en/latest/][MESA]] and =MESA-web=

:Quote:
"/An algorithm must be seen to be believed/" - D. Knuth
:end:

For a biased overview of the evolution of the field of computational
stellar physics by one of the "founding fathers" of the field, see
this [[https://www.aip.org/history-programs/niels-bohr-library/oral-histories/5091][1978 interview to R. Kippenhahn]].

*** Systematic computational uncertainties


* A different kind of simulations: rapid population synthesis

** Population synthesis

*** Semi-analytic approach to population synthesis

 - BSE: the forefather of many (*N.B.:* not /all/ rapid population
   synthesis codes)
 - [][COSMIC]: Open source and open development, =pip= installable
 - [][COMPAS]: Open source
 - [][binary_c]:
 - [][SEVN]:

*** Pre-computed and tabulated codes
 - ComBiNe (=BEC= tables of models)
 - METISSE (=MESA= tables of models)
 - MINT (= =binary_c= + =MESA= tables of models)
 - (= =PARSEC/FRANEC= tables of models)


[[https://www.as.arizona.edu/~mrenzo/materials/slides/CompAstro_MESA.pdf][Slides on stellar evolution codes (old)]]
