#+Title: 400A - Neutrinos & computational stellar evolution
#+author: Mathieu Renzo
#+email: mrenzo@arizona.edu

* Neutrino physics in stars
*Materials:* Sec. 6.5 and 12.3.1 of Onno Pols' notes, Kippenhahn chapter
9 and 10

We have almost seen all the pieces needed to make a one-dimensional
hydrostatic model of a star, including the input physics in the
quantities \kappa (opacity) and \varepsilon_{nuc}. The aim of this lecture is to unpack
the last input quantities entering in the energy conservation which
connects stellar physics with neutrino physics: \varepsilon_{\nu.}

** Summary of equations we have derived

*** Mass conservation
#+begin_latex
\begin{equation}\label{eq:mass_cont}
\frac{dr}{dm} = \frac{1}{4\pi r^{2}\rho}\ \ .
\end{equation}
#+end_latex

*** Hydrostatic equilibrium
#+begin_latex
\begin{equation}\label{eq:HSE}
\frac{dP}{dm} = -\frac{Gm}{4\pi r^{4}} \ \ ,
\end{equation}
#+end_latex
which follows from the momentum conservation equation assuming the
acceleration to be negligible *N.B.:* this last assumption could be
relaxed to add an extra term in this equation analogous to ma in F=ma.

*** Equation of state
#+begin_latex
\begin{equation}
P_\mathrm{tot} = P_\mathrm{gas} + P_\mathrm{rad} = \frac{\rho}{\mu m_{u}}k_{B}T + P_{QM} + \frac{1}{3}aT^{4}  \ \ .
\end{equation}
#+end_latex

*** Energy transport
#+begin_latex
\begin{equation}
\frac{dT}{dm} = \frac{T}{P}\frac{dP}{dm}\nabla
\end{equation}
#+end_latex
where \nabla =\partial log(T)/\partial log(P) is the local temperature gradient, equal to
the radiative gradient in stably stratified regions:
#+begin_latex
\begin{equation}
\nabla \equiv \nabla_\mathrm{rad} = \frac{3 P}{14\pi acGm T^{4}}\kappa L
\end{equation}
#+end_latex
with \kappa = (1/\kappa_{rad} + 1/\kappa_{cond})^{-1} the combination "in parallel" of the
radiative and conductive opacity (assumed to be known from atomic
physics), and \nabla \equiv \nabla_{ad} the adiabatic gradient (within \sim10^{-7-8}
precision) for convective regions. We also have a criterion
(Schwarzschild criterion) to determine which region is which.

*** Energy conservation
#+begin_latex
\begin{equation}
\frac{dL}{dm} = \varepsilon_\mathrm{nuc} -\varepsilon_{\nu} + \varepsilon_\mathrm{grav} \ \ .
\end{equation}
#+end_latex

with \varepsilon_{grav} = T\partial s/\partial t the change in internal energy and \varepsilon_{\nu}>0.

** Two types of neutrinos

For the \rho typical in stars (think of \langle\rho_{\odot}\rangle and the other
average densities you estimated in the various homeworks), neutrinos
can safely be considered as non-interacting. This means we can
consider neutrinos as ultra-relativistic mass-less particles
propagating at v \simeq c. The mass less approximation also implies that we
neglect neutrino oscillations: even if a neutrino changes leptonic
flavor, it's still going to leave the star carrying away its energy!

Therefore, any neutrino produced in the stellar interior leaves the
star in the light-crossing time R/c \le 1000 R_{\odot}/c \simeq 1000 \times
2 sec = 2000 sec which is much shorter than evolutionary timescales
(and even during shorter evolutionary phases such as silicon shell
burning, the energy carried by the neutrinos is on its way out and
nothing is going to stop it from leaving the star).

These arguments apply to both kinds of neutrinos that we can encounter
in stellar evolution, and stop working only when densities get
extremely high (\rho\ge10^{10} g cm^{-3}): at this point neutrinos can and do
start interacting with matter. Such densities are only encountered in
a collapsing core that has exhausted nuclear fuel and in neutron
stars: neutrino interactions are crucial to the physics of the
supernova explosions, but can safely be neglected before.

During the evolution of the star that sets the stage for the
explosion, we encounter two "classes" of neutrinos.

*** Nuclear neutrinos
We have already encountered processes occurring in stars: /weak nuclear
reactions/! These are needed since the main sequence (both in the pp
chain and CNO) to convert some protons into neutrons for the helium
nuclei. On the scale of r_{nuc}, the neutrino crossing time (that is the
light crossing time) is so short that we can neglect neutrino
oscillations and assume conservation of leptonic number to write down
the equations.

*N.B.:* recall that the leptonic number is +1 for the leptons electron
e^{-}, muon \mu^{-}, tau \tau^{-} and the corresponding neutrinos \nu_{e}, \nu_{\mu},
\nu_{\tau} and -1 for their antiparticles positron e^{+}, positive muon \mu^{+},
and positive \tau^{+} and the corresponding antineutrinos.

These neutrinos do carry away energy as described above, /but/ that is
just some of the energy that the exo-energetic thermonuclear reaction
would have released. Effectively, they decrease the energy gain from
releasing nuclear binding energy but they are not a net energy loss.

This allows to incorporate them in models by re-writing \varepsilon_{nuc}
\rightarrow \varepsilon_{nuc} - |\varepsilon_{\nu, nuc}|, where the neutrino term is always negative
(hence we can write it as minus an absolute value), and needs to be
calculated from nuclear physics, determining the spectrum of the
neutrino produced by a given reaction (a non-trivial task which
stellar physics leaves to neutrinos and nuclear physicists).

Particularly important for the late evolution of massive stars are
neutrinos from the so-called /URCA processes/ (named after a casino in
Rio de Janeiro because when these processes kick in the energy of the
nuclear reaction goes the same way as the money in the casino!):
#+begin_latex
\begin{equation}
 ^{A}Z+e^{-}\rightarrow^{A}(Z-1) + \nu_{e }\\
 ^{A}(Z-1)\rightarrow ^{A}Z+ e^{+} +\bar{\nu_{e}}
\end{equation}
#+end_latex

which produce one neutrino and one anti-neutrino without changing the
composition of the star. This requires that the nucleus $^{A}(Z-1)$ is
unstable to \beta^{-}-decay and the cross section for electron capture on
$^AZ$ is non-negligible, which can happen during Si core burning and
the subsequent gravitational collapse of the core once the nuclear
fuel runs out.

The nuclear neutrinos are mostly sensitive to the core temperature for
the activation of certain thermonuclear reaction chains (except for
pycno-nuclear reaction at extremely high densities where the electron
screening effectively makes the Coulomb barrier negligible).

*** Thermal neutrinos
After helium core burning, the density in the stellar cores become
sufficiently high (because of the gravothermal collapse) that
non-nuclear processes producing neutrinos start occurring. After
carbon depletion, the neutrinos produced by these processes can take
away more energy than is locally lost to photons by each stellar
layer: /evolved massive stars are neutrino stars/ L_{\nu}
\gg L_{rad} ([[https://ui.adsabs.harvard.edu/abs/1968Ap%26SS...2...96F/abstract][Fraley 1968]]).

This also effectively means that the stellar core of evolved (\sim during
and after carbon core burning) massive stars is /decoupled/ from the
stellar envelope: the /gravothermal collapse of the core occurs to
compensate the neutrino losses from the core itself/! The thermal
timescale of the core becomes \tau_{KH,\nu}\simeq GM_{core}^{2}/(2R_{core} L_{\nu}) and
the nuclear timescale becomes \tau_{nuc,\nu} = \phi f_{burn} Mc^{2}/L_{\nu} both of which
are much shorter than the timescales in the low density, photon-cooled
envelope: in the late stages of stellar evolution the envelope should
be /frozen/ and the core evolves driven by neutrino losses.

*N.B.:* it is still the energy losses driving the gravothermal collapse
because of the virial theorem that govern the evolution, but the
envelope does not have time to keep up with the core.

*N.B.:* recently, observations of early signals of stellar explosion
have questioned this picture of /frozen/ envelope: there /may/ be some
presently unknown phenomena happening on a /dynamical/ timescale of the
envelope in the final years/months of a massive star evolution that
affect the envelope. The fact that they /need to be dynamical/ to do
anything is related to the fact that the evolution of the core is sped
up by the thermal neutrino losses.

The neutrinos that do /not/ come from nuclear reactions are a real
energy /loss/ term for the star that enter in the local energy
conservation equation \varepsilon_{\nu}_{} (which is also always negative!): dL/dm =
\varepsilon_{nuc} - |\varepsilon_{\nu}| +\varepsilon_{grav}.

The /thermal/ processes producing these neutrinos typically will produce
a neutrino-antineutrino /pair/ to conserve the leptonic number.
Typically only electron neutrinos will be relevant: leptons other than
e^{\pm} are unstable and are not commonly found in stars. They fall into
several categories:


#+CAPTION: Feynman diagrams for the dominant neutrino cooling processes. The top row shows the photo-emission processes, the middle row shows the eÂ± annihilation processes, the bottom row shows the plasmon processes. The neutral (charged) current ractions are in the left (right) column. This is Figure 1 from [[https://ui.adsabs.harvard.edu/abs/1993ApJ...411..813A/abstract][Aufderheide 1993]], and Z and W represent the boson that mediate weak interactions: the left column shows interactions mediated by the neutral boson Z, while the right column shows interactions mediated by the charged boson W^{\pm}.
#+ATTR_HTML: :width 100%
[[./images/feynman_diagram_neutrinos.png]]

  - plasmon processes: $\gamma + \tilde{\gamma} \rightarrow \nu_x + \bar{\nu}_x$,
  - bremsstrahlung: $e^{-} + ^{A}Z \rightarrow e^{-} + ^{A}Z + \nu_x + \bar{\nu}_x$,
  - pair-production: $\gamma + \gamma \rightarrow \nu_x + \bar{\nu}_x$,
  - pair annihilation:  $e^{+}+e^{-} \rightarrow \nu_x + \bar{\nu}_x$ ,
  - photo-processes: $\gamma +e^{-} \rightarrow e^{-} + \nu_x + \bar{\nu}_x$,

*N.B.:* "plasmons" are collective excitations of the stellar plasma that
propagate (the analogy is with "solitons" in fluid dynamics).

*N.B.:* The Feynman diagrams of some of these processes above are
illustrating the processes (and the various pieces that contribute in
the quantum field theory calculation of the cross section), the
particles that are not "free legs" are mediators and not real
particles, do not over-interpret these diagrams as physical pictures!

Neutrino cooling processes are mostly sensitive to the core density \rho.
The typical energy carried away per neutrino-antineutrino pair is of
the order of the thermal energy of the electrons (i.e., their Fermi
energy if the region from where the neutrinos are emitted is partially
degenerate).

Lke \kappa and \varepsilon_{nuc}, the energy losses to thermal neutrinos are usually
tabulated in stellar physics codes (see especially the widely used
[[https://ui.adsabs.harvard.edu/abs/1996ApJS..102..411I/abstract][Itoh et al. 1996]]), and the figure below shows the |\varepsilon_{\nu}|
\equiv |\varepsilon_{\nu}|(T,\rho) resulting from these tables:

#+CAPTION: Neutrino energy losses on the T(\rho) plane. White lines mark the separation between regions where different neutrino emission processes dominate, the colored lines mark the T(\rho) tracks of helium cores of the labeled masses (in M_{\odot} units) computed with MESA. Credits: R. Farmer.
#+ATTR_HTML: :width 100%
[[./images/Trho_neutrinos.png]]

* Principles of computational stellar evolution

We now have finally derived/discussed all the pieces of physics
necessary to compute a stellar /structure/ model, treat its nuclear
energy generation and thus driving its /evolution/.

The description we have obtained for a spherically symmetric star is
made of *four non-linear, coupled, ordinary differential equations*
(ODE) *plus the equation of state that acts as closure condition* for
the system. Solving these equations we can:
 1. study the interior structure of modelled stars and try to learn about
    the parts of the star that are not accessible to direct
    observations (hidden inside the photosphere)
 2. study the time evolution of modelled stars, which we cannot
    observe for real stars since most evolve way too slow for us to
    follow within our lifetimes.

However, this system of coupled, non-linear ODEs is not easily solved
by hand. Since the early days of the availability of computers in the
1960s, people have been designing and leveraging /computational
techniques/ to /numerically/ solve this system of equations (see e.g.,
[[https://ui.adsabs.harvard.edu/abs/1962ApJ...135..770I/abstract][Iben & Erhman 1962]], [[https://ui.adsabs.harvard.edu/abs/1964ApJ...139..306H/abstract][Henyey 1964]]). For the rest of this lecture, we are
going to discuss some general principles behind these computational
techniques.

** The most important thing: /Computer simulations are not empirical evidence/

:Quote:
"/Traditional scientific knowledge has generally taken the form of/
/either theory or experimental data. However, where theory and/
/experiment stumble, simulations may offer a third way./" - Simulation,
Johannes Lenhard et al.
:end:

Computational techniques take a system of equations describing a
physical models (for example the equations we have derived), which
already rely on a whole variety of physical approximations (e.g.,
spherical symmetry, LTE, free-streaming neutrinos, etc.), and apply a
whole new set of /numerical/ approximations to obtain a numerical
solution.

Presumably, nature does not do /any/ of this: without opening the
philosophical question of whether nature writes down equations to
solve, it certainly does not need to make physical approximations
(while we need to do it to reason on a problem and keep it
manageable), and even less make /numerical/ approximations needed to
solve equations. At ontological level, numerical simulations are /not/
equivalent to empirical evidence! Never trust numerical results as if
they were ground truth: a computer will only do what it is told, and
we tell it our physically and numerically approximated best guess for
what we are trying to simulate which is /not/ what nature empirically
provides. I emphasize this as a person who spends most of his time
making numerical simulations! Note also how this is more general than
/just/ stellar physics: this applies to /any/ computational physics field.

Because of these, it is always crucially important to /do resolution
tests/: when performing a simulation of a physical phenomenon, you
should always test that the scientific results you obtain do not
depend on how you discretize your equations in time and space and on how
you numerically solve them. This is often a painful task, but very
important to not fool ourselves!

:Quote:
"/All models are wrong, but some are useful!/" - G. Box
:end:

In stellar physics, there is another problem: the /high non-linearity/
of the coupled system of ODEs means that there can be chaotic
behavior! A small perturbation (maybe because of a numerical error or
a small inconsistency in the tabulated input physics!) can cascade
into dramatic consequences, similar to the famous "butterfly effect"
(which was also theorized from numerical computations, but of
atmospheric physics, by [[https://en.wikipedia.org/wiki/Edward_Norton_Lorenz][E. Lorenz]]).


** Why did we limit ourselves to spherical symmetry?
Throughout the course so far we have explicitly assumed spherical
symmetry, although since the beginning we have discussed some
phenomena that can break the global spherical symmetry (e.g.,
rotation, magnetic fields, or the presence of gravity and/or
irradiation from companion stars), and we have seen phenomena (e.g.,
convection) that break the spherical symmetry locally. Without the
assumption of spherical symmetry, the equations describing our system
would become partial differential equations (PDE), changing the
mathematical and thus computational approach.

In some cases, it is possible to treat some of these by casting them
in a form that still allows a 1D formalism with ODEs (e.g., "shellular
rotation" assuming that all quantities are constant along isobars and
uses P as the independent coordinate, or using volume-weighted
equivalent potentials accounting for the gravity of a companion star).
But ultimately the physics is non-spherical, so why do we insist with
this limited approximation?

The main reason is /necessity/ (see for example [[https://ui.adsabs.harvard.edu/abs/2022ApJS..262...19J/abstract][Jermyn et al. 2022
section 5.4]]) *the contrast of scale in both space and time* required to
follow the /evolution/ of a star from birth to death (or to the current
age of the Universe, whichever comes first!) *is just too large* to be
manageable with present day /and/ with foreseeable computational
capabilities.

*** Spatial scale limitations

Consider the convective envelope in the Sun. It has a Reynolds number
Re= v_{conv} \ell/\nu \sim 10^{12}, which, using Kolmogorov's model of
turbulence implies that the turbulent cascade spans a range of scales
from L to \ell with a contrast L/\ell \sim Re^{3/4} \sim 10^{9}. To resolve this
contrast in a 3D simulation we would need this number of cells /in
each direction/, meaning \sim10^{27} points.

*** Temporal scale limitations
Consider again the Sun. The free fall timescale is generously
\tau_{ff}\sim1h, and its thermal timescale is \tau_{KH}\sim1.5\times10^{7} years,
and current age is \sim 5\times10^{9} years \simeq \tau_{nuc}. In 3D we would need to
resolve the dynamics of the gas, with timesteps \Delta t \leq \tau_{ff}. Even
considering an equal sign \Delta t=\tau_{ff} (certainly insufficient to /resolve/
the dynamics of the stellar plasma), it would take \sim \tau_{Kh} / \tau_{ff} = 10^{10}
timesteps to calculate a thermal timescale and \sim \tau_{nuc} / \tau_{ff} = 10^{12}
timesteps for a nuclear timescale.

*** Present day and future prospects

The largest present day multi-dimensional stellar hydrodynamics
simulations reach maybe up to 10^{12} resolution points, and about 10^{8}
timesteps and using lower-than-realistic Reynolds number and/or
boosting the luminosity to drive dynamical effects faster than in
reality (see [[https://ui.adsabs.harvard.edu/abs/2022ApJ...928L..10A/abstract][Anders et al. 2022]] or [[https://ui.adsabs.harvard.edu/abs/2024MNRAS.531.1316T/abstract][Thompson et al. 2024]]).

Assuming that Moore's law (the number of transistors in a CPU roughly
doubles every year) - an assumptions that may clash with the
engineering reality, it will take several decades to have a
numerically resolved 3D simulation of convection in a star for a
convective turnover timescale, and longer for thermal and nuclear
timescale: 1D will remain necessary, and we need to keep representing
the complex multi-scale, multi-physics, and multi-dimensional problem
of stellar evolution considering only variations along the radial
direction!

Nevertheless, 3D stellar hydrodynamics of restricted problems ("box in
a star" approach, short timescales such as stellar explosions) are
possible, and stellar /structure/ simulations in 2D are also at the
forefront of possibilities (see e.g., [[https://ui.adsabs.harvard.edu/abs/2023A%26A...677L...5M/abstract][Mombarag et al. 2023]]).

** Boundary conditions
So, for the foreseeable future 1D stellar structure and evolution
calculation using the set of equations we derived. To solve them, we
need boundary conditions. These are crucial in determining the
solution of the structure at each timestep!

For the stellar problem, we need to specify boundary conditions at two
locations.

*** Central boundary conditions

These are fairly intuitive:
 - r(m=0) = 0. This is necessary to keep the local density \rho \sim m/r^{3} finite.
 - L(m=0) = 0. This is necessary to keep the energy generation per
   unit volume finite (as the volume goes to zero)

However, we have 4 ODEs and these are only two boundary conditions, so
the system is still undetermined. The central pressure and density are
not a priori known (we can estimate them, but that is not precise
enough!).

*** Surface boundary conditions

We need to turn to the surface to get observationally informed
boundary conditions. Remember that from the point of view of a
detailed stellar evolution code, which assumes LTE to solve for the
internal structure, the "surface" (meaning: the outer boundary) is
usually defined at the photosphere. This is by definition the
"idealized" surface where T=T_{eff} which corresponds to the location
outside of which LTE is not a good assumption anymore, the radiation
field is /not/ isotropic, and the problem becomes the calculation of a
stellar /atmosphere/.

Accepting to externalize the problem of stellar atmosphere (which we
will treat in more detail [[./notes-lecture-radTrans.org][in a future lecture]]), we already have
written one of the missing outer boundary conditions at mass
coordinate equal to the total mass of the star (m=M):
 - T(m=M) = T_{eff}, where T_{eff} is /defined/ as the temperature of a black
   body producing the same luminosity as the star: L=4\pi R^{2}\sigma T_{eff}
   with R=r(M).

For the final missing boundary condition, we need to specify the outer
pressure P(r=R) at R=r(M). This typically comes from imposing a /smooth/
transition from the stellar interior (inside, T \ge T_{eff}) and the
stellar atmosphere (outside, T \le T_{edd}), which requires calculating the
pressure in the stellar atmosphere where the assumptions we made so
far, and consequently the equations we wrote do not hold.

:Question:
- *Q*: Why should P be smooth? (*Hint:* think of dP/dr!)
:end:

** Solving strategies
Let's assume we have a way to specify P(r=R), and postpone the
discussion of stellar atmosphere to a [[./notes-lecture-radTrans.org][future lecture]].
We then have 4 coupled non-linear ODEs with 4 boundary conditions (2
at the center and 2 at the surface), and the EOS as a closure
condition. How can we solve them numerically?

*** Discretization
First, to represent the system of equations in a computer we want to
discretize them, that is convert every derivative into a /finite
difference/. This can be done in various ways, each with specific
advantages and disadvantages. The simplest is a first-order forward
discretization of the form:

#+begin_latex
\begin{equation}
\frac{df}{dx} \rightarrow \frac{f(x_{k+1})-f(x_{k})}{x_{k+1}-x_{k}} \ \ ,
\end{equation}
#+end_latex
where f and x are a generic function and variable, and the index k
labels the discretized points.

For example, if x=m, the index k will label which cell of the
mass-coordinate "mesh" we are considering and m_{k+1} - m_{k} = \Delta m_{k} is the
local resolution in mass at location k, while if x=t, then k will
label the "timestep" we are considering, and t_{k+1}-t_{k} = \Delta t_{k+1} is the
timestep size.

*N.B.:* typically both the spatial resolution \Delta m_{k} and the temporal
resolution \Delta t_{k} are /adaptive/, meaning the stellar evolution code will
put more mesh points where / take more timesteps when quantities vary
more rapidly.

*N.B.:* Nature \gg numerical models, because nature does not need to do
this!

#+CAPTION: Schematic representation of the spatial mesh in MESA. Intensive quantities (T, \rho, P) that do not depend on the amount matter are defined at the cell "center", while extensive quantities (m, L) are defined at the cell "boundaries". This is Figure 9 in [[https://ui.adsabs.harvard.edu/abs/2011ApJS..192....3P/abstract][Paxton et al. 2011]].
#+ATTR_HTML: :width 100%
[[./images/mesh.png]]

With the discretization in mind, we can rewrite the ODEs as algebraic
equations:

#+begin_latex
\begin{equation}
\frac{dm}{dr}=4\pi r^2\rho   \Leftrightarrow   \ln(r_k) = \frac{1}{3}\ln\left( r_{k+1}^{3} +\frac{3}{4\pi}\frac{dm_k}{\rho_k}\right)
\end{equation}

\begin{equation}
\frac{dP}{dr}=-\frac{Gm(r)\rho}{r^2} \Leftrightarrow \frac{P_{k-1} - P_k}{0.5(dm_{k-1} - dm_k)} = - \frac{G m_k}{4\pi r_k^4} \\
\end{equation}

\begin{equation}
\frac{dT}{dr} = - \frac{3}{16\pi a c}\frac{\kappa\rho L}{r^2 T^3}  \Leftrightarrow \frac{T_{k-1} - T_k}{(dm_{k-1} - dm_k)/2} = -\nabla_{T,k}\left(\frac{dP}{dm}\bigg|_k\right)\frac{\tilde{T_k}}{\tilde{P_k}} \\
\end{equation}

\begin{equation}
\frac{dL}{dr}=4\pi r^{2}\rho (\varepsilon_\mathrm{nuc} - \varepsilon_{\nu} +\varepsilon_\mathrm{grav})  \Leftrightarrow L_k-L_{k+1} = dm_k (\varepsilon_\mathrm{nuc}-\varepsilon_\nu + \varepsilon_\mathrm{grav})
\end{equation}

\begin{equation}
P\equiv P(\rho,\mu,T)  \Leftrightarrow  P\equiv P(\rho,\mu,T)
\end{equation}

\begin{equation}
\frac{dX_i}{dt}\bigg|_{r} = \left[ \sum\limits_j \mathcal{P}_{j,i}(T,\rho)
    -\sum\limits_k \mathcal{D}_{i,k}(T,\rho)\right] + \left( D_i
    \nabla^2X_i\phantom{\bigg|} \right)\\
\Leftrightarrow \\
   X_{i,k}(t_n+\Delta t_{n+1}) = X_{i,k}(t_n) + \Delta
    t_{n+1}\left(\frac{dX_{i,k}}{dt}\right)_\mathrm{nuc} +
    \frac{\left(X_{i,k}-X_{i,k-1} \right)D_{k}\Delta t_{n+1}}{0.5(dm_{k-1} - dm_k)}
\end{equation}
#+end_latex

Where, when going from the physical model to the
numerical implementation:
- we use m rather than r as independent coordinate
- the mass continuity if re-formulated in terms of natural logarithm
  or r instead or r itself (to keep numbers smaller)


Now that we have transformed a set of ODEs into a set of algebraic
equations, the stellar structure and evolution problem is reduced to
solving a matrix equation:

#+CAPTION: Section of an example of the matrix to solve. Black dots are non-zero entries, meaning the variables are coupled by an equation. Vertical dashed lines denote blocks of the matrix for cell =k-1=, =k=, and =k+1= respectively, red dotted lines separate structural variables and compositional variables. This is Fig. 47 of [[https://ui.adsabs.harvard.edu/abs/2013ApJS..208....4P/abstract][Paxton et al. 2013]].
#+ATTR_HTML: :width 100%
[[./images/matrix_mesa.png]]

Writing this in a symbolic compact form we an array of quantities X(t)
of length equal to the number of mesh points for our spatial
discretization times the number of variables, and a matrix A which
represents how all the entries of X are coupled to each other in the
algebraic form of the equations: AX(t_{k}) = X(t_{k+1}).

To solve this we could consider two approaches:
- *Explicit methods*: in this case X(t_{k+1}) is expressed as a function of
  X(t_{k}). This however will require resolving the /local/ dynamics (and
  be limited by the sound crossing time), making it impossible to perform a
  calculation for the /evolution/ of the star
- *Implicit methods:* in this case we write a function F(X(t_{k}), X(t_{k+1}))
  = 0 (e.g., AX(t_{k}) - X(t_{k+1}) = 0), and by solving the homogeneous
  equation we have obtained we derive X(t_{k+1}). Implicit methods are
  preferred in stellar evolution as they are not limited by the sound
  crossing time.

For each of these methods, we still need to specify a solver.
Typically stellar evolution codes rely on generalized first order
Newton Raphson solvers.

*** Shooting method

*** Henyey method

*** Evolution splitting

** Open science: [[https://docs.mesastar.org/en/latest/][MESA]] and =MESA-web=

:Quote:
"/An algorithm must be seen to be believed/" - D. Knuth
:end:

For a biased overview of the evolution of the field of computational
stellar physics by one of the "founding fathers" of the field, see
this [[https://www.aip.org/history-programs/niels-bohr-library/oral-histories/5091][1978 interview to R. Kippenhahn]].

*** TODO Systematic computational uncertainties

** Summary
 1. take a star, which is a complex multi-scale, multi-physics,
    multi-dimensional object
 2. obtain from other fields of physics input for \varepsilon_{nuc}, \varepsilon_{\nu},
    \kappa, and the EOS
 3. write down an approximate physical model assuming spherical
    symmetry, going from a multi-dimensional object to a continuous
    line along a spatial direction
 4. discretize that line into "chunks" of (variable) size \Delta m_{k}
 5. use an implicit first-order generalized Newton-Raphson solver to
    determine how variables at the points \Delta m_{k} vary within discrete
    (variable) time interval \Delta t_{k}.
 6. *make sure that the scientific results you obtain do not depend on
    any of steps 2-5*.

* Population synthesis

As we saw since the [[./notes-lecture-CMD-HRD.org][lecture on the CMD/HRD]], in stellar physics it is
often necessary to rely on /population studies/ to infer something about
the physics of the star. Moreover, when thinking about galaxies (e.g.,
integrated light from a far away galaxy where not all stars are
resolved), we definitely need /populations/. Population studies are also
needed to predict /rates/ of phenomena (e.g., supernovae, gravitational
wave mergers, etc.).

The practice of /combining/ many stellar models to make a population is
generally referred to as /population synthesis/. This can be done with
/detailed/ models, such as the one coming from codes that solve the
equations of stellar structure (e.g., MESA, KEPLER, FRANEC, PARSEC,
HOSHI, etc.).

However, often there are many things one may want to change for /fixed/
stellar evolution (e.g., the initial distribution of stars, or their
metallicity distribution, or how they interact in binaries or higher
multiplicity systems), and recomputing all the models is not
necessary.

Since the 1990s, there has been the development of "semi-analytic"
techniques based on implementing polynomial fits to a set of stellar
models (e.g., [[https://ui.adsabs.harvard.edu/abs/1998MNRAS.298..525P/abstract][Pols et al. 1998]]), and use these to simulate the
evolution of stars - producing a /rapid/ population synthesis. Coupling
these to analytic models for the interaction of binaries (which are
used by detailed stellar codes too!), one can get /rapid/ population
synthesis.

More recently, there has been a move to use directly tabulated results
from detailed stellar evolution codes, instead of analytic fits to
those tables, which allows to track more details (and more easily
update the stellar models) for a small computational price that is now
affordable.

Below is an (incomplete, biased) list of some of these codes.

** Semi-analytic approach to population synthesis

 - BSE: the forefather of many (*N.B.:* not /all/ rapid population synthesis codes)
 - [[https://cosmic-popsynth.github.io/][COSMIC]]: Open source and open development, =pip= installable
 - [[https://compas.science/][COMPAS]]: Open source
 - [[https://binary_c.gitlab.io/][binary_c]]: Open source, python front-end available, can be [[https://r-izzard.surrey.ac.uk/cgi-bin/binary5.cgi][run on online]] (similar to =MESA-web=)
 - ...

** Pre-computed and tabulated codes
 - ComBiNe (=BEC= tables of models)
 - METISSE (=MESA= tables of models)
 - MINT (= =binary_c= + =MESA= tables of models)
 - [[https://web.oapd.inaf.it/mapelli/SEVN.tar.gz][SEVN]] (based on =PARSEC/FRANEC= tables of models)
 - ...
